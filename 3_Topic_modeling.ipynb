{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling Lab\n",
    "\n",
    "### To do list:\n",
    "- Use sk-learn because\n",
    "    - It has both LDA and NMF\n",
    "    - It is the same API they'll use for many stats and ML tasks\n",
    "    - There's a good example guide here: https://medium.com/@aneesha/topic-modeling-with-scikit-learn-e80d33668730\n",
    "    \n",
    "- Steps \n",
    "    - preprocessing (use 'clean' data from lab notebook 1)\n",
    "    - fitting LDA\n",
    "    - viewing, interpreting topics\n",
    "    - cross tabs of topics and personal attributes of interest\n",
    "    - fitting NMF\n",
    "    - viewing, interpreting results\n",
    "    - comparing LDA & NMF topics (deal with alignment)\n",
    "    - cross tabs\n",
    "    - compare LDA & NMF cross tabs (undermine singular, objective truth)\n",
    "    \n",
    "- Functionality\n",
    "    - Display topics found\n",
    "    - Undo stems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Setup\n",
    "#### Import the packages we'll use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in our data and peak at the first rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles = pd.read_csv('data/clean_profiles.tsv', sep='\\t')\n",
    "#profiles = profiles.sample(5000)\n",
    "profiles.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean up the text to remove HTML and other things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    t = BeautifulSoup(text, 'lxml').get_text()\n",
    "    t = t.lower()\n",
    "    \n",
    "    bad_words = ['http', 'www', '\\nnan']\n",
    "    \n",
    "    for b in bad_words:\n",
    "        t = t.replace(b, '')\n",
    "    \n",
    "    return t\n",
    "\n",
    "profiles['clean'] = profiles.text.apply(clean)\n",
    "profiles.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Topic Modeling\n",
    "#### Some parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#how many topics we want our model to find\n",
    "ntopics = 15\n",
    "\n",
    "#how many top words we want to display for each topic\n",
    "nshow = 10\n",
    "\n",
    "#what we will use as our documents, here the cleaned up text of each profile\n",
    "documents = profiles.clean.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert text to count vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2, max_features=1000, \n",
    "                                stop_words='english')\n",
    "\n",
    "print(\"Vectorizing text by word counts...\")\n",
    "tf_text = tf_vectorizer.fit_transform(documents)\n",
    "\n",
    "tmp = tf_text.get_shape()\n",
    "print(\"Our transformed text has\", tmp[0], \"rows and\", tmp[1], \"columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "\n",
    "print(\"The first few words (alphabetically) are:\\n\", tf_feature_names[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build a topic model using LDA\n",
    "\n",
    "- LDA can be a little slow. We'll use a faster method later on.\n",
    "- Set `n_jobs=` to the number of processors you want to use to compute LDA. If you set it to `-1`, it will use all available processors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LatentDirichletAllocation(n_components=ntopics, max_iter=10, \n",
    "                                  learning_method='online', n_jobs=-1)\n",
    "\n",
    "print('Performing LDA on vectors...')\n",
    "lda = model.fit(tf_text)\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a function for showing our topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, n_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        words = []\n",
    "        topic = topic.argsort() \n",
    "        topic = topic[:-n_words - 1:-1]\n",
    "        for i in topic:\n",
    "            words.append(feature_names[i])\n",
    "            \n",
    "        print(\"Topic\", topic_idx, \":  \", \" \".join(words))\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show our topics with the top words in each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_topics(lda, tf_feature_names, n_words=nshow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try again with a different model: NMF\n",
    "#### Convert the words to a TF-IDF vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, max_features=1000, \n",
    "                                   stop_words='english')\n",
    "\n",
    "print(\"Vectorizing text by TF-IDF...\")\n",
    "tfidf_text = tfidf_vectorizer.fit_transform(documents)\n",
    "tmp = tfidf_text.get_shape()\n",
    "print(\"Our transformed text has\", tmp[0], \"rows and\", tmp[1], \"columns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The features are the same, because they are just the list of words in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "print(\"The first few words (alphabetically) are:\\n\", tfidf_feature_names[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build a topic model using NMF\n",
    "\n",
    "- NMF is faster than LDA and often works a little better for small documents.\n",
    "- NMF has no `n_jobs=` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NMF(n_components=ntopics, alpha=.1, l1_ratio=.5, init='nndsvd')\n",
    "\n",
    "print('Performing NMF on vectors...')\n",
    "nmf = model.fit(tfidf_text)\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show our topics with the top words in each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_topics(nmf, tfidf_feature_names, nshow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
