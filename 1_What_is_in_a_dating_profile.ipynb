{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What's in an online dating profile? \n",
    "\n",
    "People say a lot about themselves in online dating profiles, especially on sites like OKCupid that encourage people to answer questions. Thus, we can learn a lot about people by studying what they write. OKC has made some of their profile data from San Fransisco public. We will be using that data in this lab to explore different cultural questions. \n",
    "\n",
    "Our first question is whether and how men and women talk about themselves differently in their profiles. Popular culture is constantly telling us that men and women have different interests, hobbies, and relationship goals. Yet there are also many examples of women who like stereotypically masculine things and men who like feminine ones. This is especially interesting in online dating, because people are seeking partners with similar interests and relationship goals. Finding a partner would be hard for straight men and women if these two groups had very different interests. \n",
    "\n",
    "OKC gave us 2,420,409 profiles though -- way too much to read! Computers can read them all and tell us how common different words are. So our first approach will be simple. We can ask \n",
    "1. Which words are used the most by men and women? \n",
    "2. Which words are used often by men but not women, and vice versa? \n",
    "\n",
    "At the end of the lab, you'll be able to ask this question about other social groups too (like sexual orientation, race/ethnicity, and level of education)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the libraries we'll use.\n",
    "`%matplotlib inline` lets us see charts and plots right here in the notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import regexp_tokenize \n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "profiles = pd.read_csv('data/profiles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random subsample so this doesn't crash\n",
    "profiles = profiles.sample(20000)\n",
    "profiles = profiles.reset_index(drop=True)\n",
    "profiles.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A little housekeeping...\n",
    "Expand for more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The OKC data has 10 different columns with profile text, one for each long-answer question in users' profiles.\n",
    "- We want to look at all of the profile text, so this cell merges it all together in a new column called `text`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "essay_cols = ['essay0', 'essay1', 'essay2', 'essay3', 'essay4', 'essay5', 'essay6', \n",
    "              'essay7', 'essay8', 'essay9']\n",
    "\n",
    "def concat(row, cols):\n",
    "    tmp = []\n",
    "    for c in cols:\n",
    "        tmp.append(str(row[c]))\n",
    "    new = '\\n'.join(tmp)\n",
    "    return new\n",
    "\n",
    "profiles['text'] = profiles.apply(concat, axis=1, cols=essay_cols)\n",
    "\n",
    "profiles = profiles[['age', 'body_type', 'diet', 'drinks', 'drugs', 'education', \n",
    "                     'ethnicity', 'height', 'income', 'job', 'last_online', \n",
    "                     'location', 'offspring', 'orientation', 'pets', 'religion', \n",
    "                     'sex', 'sign', 'smokes', 'speaks', 'status', 'text']]\n",
    "\n",
    "profiles.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's peak at an example of the text so we know what we're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles.text[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We want to split the text into words.\n",
    "Expand for details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can do this by applying the `split()` function to text in every profile. \n",
    "- Notice, however, that this is a little messy.\n",
    "    - `split()` is just cutting up the text based on the spaces, leaving the punctuation and some HTML things mized in with our words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A first try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = profiles['text'].apply(lambda x: x.split())\n",
    "tmp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting text from words\n",
    "Expand for details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define a function to clean up the text a bit more. It does a few things:\n",
    "- Removes HTML code from the text using BeautifulSoup. (Remember, we want just the words people actually typed.) \n",
    "- Converts all of the text to lowercase, so that `Hello`, `hello`, `\"HeLlO`, and `HELLO` all look the same to the computer.\n",
    "- Uses the Natural Language Tool Kit (`nltk`) to tokenize the remaining text. \n",
    "    - \"Tokenize\" is jargon for splitting text into \"tokens.\" Tokens are usually words, but they could be sentences, paragraphs, letters, or whatever we needed. \n",
    "    - The nltk tokenizers are much smarter than the simple `string.split()` function we used before. This one (which we imported in the beginning) selects the words, but ignores the whitespace and punctuation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A second try"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_words = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \n",
    "              'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', \n",
    "              'himself', 'she', 'her', 'hers', 'herself', 'they', 'them', 'their',\n",
    "              'theirs', 'themselves']\n",
    "\n",
    "sw = set(stopwords.words('english'))\n",
    "\n",
    "for k in keep_words:\n",
    "    sw.discard(k) #could use remove if we wanted keyerrors\n",
    "    \n",
    "print(sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    t = BeautifulSoup(text, 'lxml').get_text()\n",
    "    \n",
    "    bad_words = ['http', 'www', '\\nnan']\n",
    "    for b in bad_words:\n",
    "        t = t.replace(b, '')\n",
    "    \n",
    "    t = t.lower()\n",
    "    t = regexp_tokenize(t, '\\w+')\n",
    "    \n",
    "    final = []\n",
    "    for w in t:\n",
    "        if w not in sw:\n",
    "            final.append(w)\n",
    "    \n",
    "    return final\n",
    "\n",
    "profiles['tokens'] = profiles['text'].apply(clean)\n",
    "profiles.tokens.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Comparing the words used by men and women"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "men = profiles[(profiles['sex'] == 'm') & (profiles['orientation'] == 'straight')]\n",
    "women = profiles[(profiles['sex'] == 'f') & (profiles['orientation'] == 'straight')]\n",
    "\n",
    "men.tokens.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Counting how often each gender uses each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(series):\n",
    "    l = []\n",
    "    for x in series:\n",
    "        l.extend(x) #each x is a list we want to unnest\n",
    "    return l\n",
    "\n",
    "tmp = flatten(men.tokens)\n",
    "\n",
    "mens_words = Counter(tmp)\n",
    "mens_words.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = flatten(women.tokens)\n",
    "\n",
    "womens_words = Counter(tmp)\n",
    "womens_words.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert those word counts to frequencies (percent of total words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = {'women': womens_words,\n",
    "       'men': mens_words\n",
    "      }\n",
    "\n",
    "popular_words = pd.DataFrame(tmp)\n",
    "\n",
    "popular_words['men'] = (popular_words['men'] /  popular_words['men'].sum())*100\n",
    "popular_words['women'] = (popular_words['women'] /  popular_words['women'].sum())*100\n",
    "\n",
    "popular_words.sort_values(by='men', inplace=True, ascending=False)\n",
    "popular_words.head().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_words['max'] = popular_words.max(axis=1)\n",
    "popular_words = popular_words.sort_values(by='max', ascending=False)\n",
    "popular_words.head(10).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### See the distribution of word popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_words['max'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look at just the 1000 most popular words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_words = popular_words.head(1000)\n",
    "print(popular_words.shape)\n",
    "popular_words['max'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure out which words are popular with one gender but not the other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def times_diff(row):\n",
    "    if row.men > row.women:\n",
    "        return row.men / row.women\n",
    "    else:\n",
    "        return -1 * (row.women / row.men)\n",
    "    \n",
    "popular_words['times_diff'] = popular_words.apply(times_diff, axis=1)\n",
    "popular_words = popular_words.sort_values(by='max', ascending=False)\n",
    "\n",
    "print('Most popular words:')\n",
    "popular_words.head(10).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_words = popular_words.sort_values(by='times_diff', ascending=False)\n",
    "\n",
    "print('Words men use more than women:')\n",
    "popular_words.head(15).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_words = popular_words.sort_values(by='times_diff', ascending=True)\n",
    "\n",
    "print('Words women use more than men:')\n",
    "popular_words.head(15).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#snowball English (aka porter2) is improved over the porter stemmer\n",
    "stemmer = SnowballStemmer(\"english\") \n",
    "\n",
    "def stem(t):\n",
    "    out = []\n",
    "    for w in t:\n",
    "        out.append(stemmer.stem(w))\n",
    "    return out\n",
    "\n",
    "profiles['stems'] = profiles['tokens'].apply(stem)\n",
    "profiles.stems.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's try it again with stems this time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for summarizing word use by a trait\n",
    "def times_diff2(row, group, ref):\n",
    "    if row[ref] > row[group]:\n",
    "        return -1 * (row[ref] / row[group])\n",
    "    else:\n",
    "        return row[group] / row[ref]\n",
    "\n",
    "#normally we wouldn't paste this function here but it helps to show in the lab\n",
    "def flatten(series):\n",
    "    l = []\n",
    "    for x in series:\n",
    "        l.extend(x) #each x is a list we want to unnest\n",
    "    return l\n",
    "    \n",
    "def flatten2(series):\n",
    "    l = []\n",
    "    for x in series:\n",
    "        tmp = set(x) #make the tokens into a set, thus dropping repeats\n",
    "        tmp = list(tmp) #turn it back into a list we can attach to the other lists\n",
    "        l.extend(tmp) \n",
    "    return l\n",
    "\n",
    "def word_use(df, att, ref, per_person=False):\n",
    "    types = list(df[att].value_counts().index.values)\n",
    "    data = {}\n",
    "    lens = {}\n",
    "    \n",
    "    for t in types:\n",
    "        tmp = df[df[att] == t].stems\n",
    "        lens[t] = len(tmp)\n",
    "        \n",
    "        if per_person:\n",
    "            tmp = flatten2(tmp)\n",
    "        else:\n",
    "            tmp = flatten(tmp)\n",
    "        data[t] = Counter(tmp)\n",
    "        \n",
    "    popular_words = pd.DataFrame(data)\n",
    "    \n",
    "    for t in types:\n",
    "        n = 0\n",
    "        \n",
    "        if per_person:\n",
    "            n = lens[t]\n",
    "        else:\n",
    "            n = popular_words[t].sum()\n",
    "        \n",
    "        popular_words[t] = (popular_words[t] / n) * 100\n",
    "    \n",
    "    #find overall most popular words, select the top 1000\n",
    "    popular_words['max'] = popular_words.max(axis=1)\n",
    "    popular_words = popular_words.sort_values(by='max', ascending=False)\n",
    "    popular_words = popular_words.head(1000)\n",
    "    \n",
    "    for t in types:\n",
    "        if t != ref:\n",
    "            popular_words['times_diff_'+t] = popular_words.apply(times_diff2, \n",
    "                                                                 group=t, ref=ref, \n",
    "                                                                 axis=1)\n",
    "\n",
    "    \n",
    "    return popular_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_words = word_use(profiles, att='sex', ref='m')\n",
    "popular_words = popular_words.sort_values(by='times_diff_f', ascending=True)\n",
    "print(\"Men's words:\")\n",
    "popular_words.head(10).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_words = popular_words.sort_values(by='times_diff_f', ascending=False)\n",
    "print(\"Women's words:\")\n",
    "popular_words.head(10).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's try it again, but with percent of profiles rather than percent of words\n",
    "not all profiles have the same number of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_words = word_use(profiles, att='sex', ref='m', per_person=True)\n",
    "popular_words = popular_words.sort_values(by='times_diff_f', ascending=True)\n",
    "print(\"Men's words:\")\n",
    "popular_words.head(10).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_words = popular_words.sort_values(by='times_diff_f', ascending=False)\n",
    "print(\"Women's words:\")\n",
    "popular_words.head(10).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Try it with another trait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = word_use(profiles, att='orientation', ref='straight', per_person=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result.sort_values(by='times_diff_gay', ascending=False)\n",
    "result.head(10).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result.sort_values(by='times_diff_bisexual', ascending=False)\n",
    "result.head(10).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result.sort_values(by='times_diff_gay', ascending=True)\n",
    "result.head(10).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles.ethnicity.value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
