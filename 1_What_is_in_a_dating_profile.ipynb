{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What's in an online dating profile? \n",
    "\n",
    "People say a lot about themselves in online dating profiles, especially on sites like OKCupid that encourage people to answer questions. Thus, we can learn a lot about people by studying what they write. OKC has made some of their profile data from San Fransisco public. We will be using that data in this lab to explore different cultural questions. \n",
    "\n",
    "Our first question is whether and how men and women talk about themselves differently in their profiles. Popular culture is constantly telling us that men and women have different interests, hobbies, and relationship goals. Yet there are also many examples of women who like stereotypically masculine things and men who like feminine ones. This is especially interesting in online dating, because people are seeking partners with similar interests and relationship goals. Finding a partner would be hard for straight men and women if these two groups had very different interests. \n",
    "\n",
    "OKC shared 59,946 profiles though -- way too many to read! Computers can read them all and tell us how common different words are. So our first approach will be simple. We can ask \n",
    "1. Which words are used the most by men and women? \n",
    "2. Which words are used often by men but not women, and vice versa? \n",
    "\n",
    "At the end of the lab, you'll be able to ask this question about other social groups too (like sexual orientation, race/ethnicity, age, level of education, even whether someone likes dogs or cats).\n",
    "\n",
    "@Author: [Jeff Lockhart](http://www-personal.umich.edu/~jwlock/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Setup\n",
    "### Import the packages we'll use.\n",
    "- Packages contain a bunch of useful code others have written to make our jobs easier.\n",
    "- `%matplotlib inline` lets us see charts and plots right here in the notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import regexp_tokenize \n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read our data.\n",
    "**Before you run this code:** make sure that you have downloaded the data.\n",
    "- Go to [https://github.com/rudeboybert/JSE_OkCupid](https://github.com/rudeboybert/JSE_OkCupid). \n",
    "    - If you're new to github, the easiest way is to right-click each file and \"save link as.\" \n",
    "    - You can also clone or download the whole repository. \n",
    "- Download the `okcupid_codebook.txt` and `profiles.csv.zip` files and save them in the `data` directory (folder).\n",
    "- Unzip the profiles file in the same place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles = pd.read_csv('data/profiles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show how many rows and columns the data has\n",
    "profiles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show the names of the columns\n",
    "profiles.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show the first few rows of data\n",
    "profiles.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, a little housekeeping...\n",
    "You don't need to worry about the code here right now. Just run it and continue reading below. Expand for more details on how it works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The OKC data has 10 different columns with profile text, one for each long-answer question in users' profiles. We want to look at all of the profile text, so this merges it all together in a new column called `text`.\n",
    "- This code also simplifies the categories people pick for other things like level of education, the pets they have, etc.\n",
    "- It removes people under 18 and over 60.\n",
    "- It saves this cleaner version of the data so we can use it later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The code\n",
    "This cell tells python a bunch of information about our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "essay_cols = ['essay0', 'essay1', 'essay2', 'essay3', 'essay4', 'essay5', 'essay6', \n",
    "              'essay7', 'essay8', 'essay9']\n",
    "\n",
    "ed_levels = {'<HS': ['dropped out of high school', 'working on high school'],\n",
    "             'HS': ['graduated from high school', 'working on college/university', \n",
    "                    'two-year college', 'dropped out of college/university', \n",
    "                    'high school'], \n",
    "             'BA': ['graduated from college/university', \n",
    "                    'working on masters program', 'working on ph.d program', \n",
    "                    'college/university', 'working on law school', \n",
    "                    'dropped out of masters program', \n",
    "                    'dropped out of ph.d program', 'dropped out of law school', \n",
    "                    'dropped out of med school'],\n",
    "             'Grad_Pro': ['graduated from masters program',\n",
    "                          'graduated from ph.d program',                           \n",
    "                          'graduated from law school', \n",
    "                          'graduated from med school', 'masters program', \n",
    "                          'ph.d program', 'law school', 'med school']\n",
    "            }\n",
    "\n",
    "bodies = {'average': ['average'], \n",
    "          'fit': ['fit', 'athletic', 'jacked'], \n",
    "          'thin': ['thin', 'skinny'], \n",
    "          'overweight': ['curvey', 'a little extra', 'full figured', 'overweight']\n",
    "         }\n",
    "\n",
    "smoke = {'no': ['no'], np.nan: ['nan']}\n",
    "\n",
    "kids = {'yes': ['has a kid', 'has kids']}\n",
    "\n",
    "has_pets = {'yes': ['has']}\n",
    "\n",
    "ethn = {'White': ['white', 'middle eastern', 'middle eastern, white'], \n",
    "        'Asian': ['asian', 'indian', 'asian, pacific islander'], \n",
    "        'Black': ['black']\n",
    "       }   \n",
    "\n",
    "ethn2 = {'Latinx': ['latin'], 'multiple': [','], np.nan: ['nan']}   \n",
    "\n",
    "drinks = {'no': ['rarely', 'not at all']}\n",
    "\n",
    "drugs = {'no': ['never']}\n",
    "\n",
    "jobs = {'education': ['student', 'education'], \n",
    "        'STEM': ['science', 'computer'], \n",
    "        'business': ['sales', 'executive', 'banking'], \n",
    "        'creative': ['artistic', 'entertainment'], \n",
    "        'med_law': ['medicine', 'law'],\n",
    "        np.nan: ['nan']\n",
    "       }\n",
    "\n",
    "religion = {'none': ['agnosticism', 'atheism'],\n",
    "            'catholicism': ['catholicism'],\n",
    "            'christianity': ['christianity'],\n",
    "            'judaism': ['judaism'],\n",
    "            'buddhism': ['buddhism'],\n",
    "            np.nan: ['nan']\n",
    "           }\n",
    "\n",
    "languages = {'multiple': [',']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell defines some functions we'll use to clean up the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat(row, cols):\n",
    "    tmp = []\n",
    "    for c in cols:\n",
    "        tmp.append(str(row[c]))\n",
    "    new = '\\n'.join(tmp)\n",
    "    return new\n",
    "\n",
    "def recode(text, dictionary, default=np.nan):\n",
    "    '''Function for recoding categories in a column based on exact matches'''\n",
    "    out = default\n",
    "    text = str(text)\n",
    "    \n",
    "    for x in dictionary.keys():\n",
    "        for y in dictionary[x]:\n",
    "            if y == text: #exact match\n",
    "                out = x\n",
    "                return out\n",
    "    return out\n",
    "\n",
    "def recode_fuzzy(text, dictionary, default=np.nan):\n",
    "    '''Function for recoding categories in a column based on partial matches'''\n",
    "    out = default\n",
    "    text = str(text)\n",
    "    \n",
    "    for x in dictionary.keys():\n",
    "        for y in dictionary[x]:\n",
    "            if y in text: #partial match\n",
    "                out = x\n",
    "                return out\n",
    "    return out\n",
    "\n",
    "\n",
    "def which_pets(t, criterion='has'):\n",
    "    '''Function for determining which pets someone has or likes'''\n",
    "    d = False\n",
    "    c = False\n",
    "    t = str(t)\n",
    "    p = 'neither'\n",
    "    if t == 'nan':\n",
    "        p = np.nan\n",
    "    \n",
    "    if 'has dogs' in t:\n",
    "        d = True\n",
    "    if 'has cats' in t:\n",
    "        c = True\n",
    "        \n",
    "    if criterion == 'likes':\n",
    "        if 'likes dogs' in t:\n",
    "            if 'dislikes dogs' not in t:\n",
    "                d = True\n",
    "        if 'likes cats' in t:\n",
    "            if 'dislikes cats' not in t:\n",
    "                c = True\n",
    "        \n",
    "    if c and d:\n",
    "        p = 'both'\n",
    "    elif c:\n",
    "        p = 'cats'\n",
    "    elif d:\n",
    "        p = 'dogs'\n",
    "        \n",
    "    return p\n",
    "\n",
    "def census_2010_ethnicity(t):\n",
    "    '''\n",
    "    Function gathers choices for this question gathered by the US Census 2010.\n",
    "    It deviates from the census by creating exclusive Latinx category. Selecting \n",
    "    just 'latin' and nothing else was the 3rd most frequent ethnicity in this \n",
    "    data. The discision to include people who identified 'latin' and another race\n",
    "    is based in research on Latinx people's experience with the US Census, but \n",
    "    like all racial and ethnic categorization systems, it is flawed. \n",
    "    '''\n",
    "    text = str(t)\n",
    "    \n",
    "    e = recode(text, ethn, default='other')\n",
    "    if 'other' == e:\n",
    "        e = recode_fuzzy(text, ethn2, default='other')\n",
    "    \n",
    "    return e\n",
    "\n",
    "def height(inches):\n",
    "    h = 'under_6'\n",
    "    if inches >= 72:\n",
    "        h = 'over_6'\n",
    "    return h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do the clean up\n",
    "This cell calls the functions we created in the last cell, along with the information about our data from the cell before it, to actually clean our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove people 60+ and 17-\n",
    "profiles = profiles[(profiles.age < 60) & (profiles.age > 17)]\n",
    "\n",
    "#recode categorical columns into simpler categories\n",
    "profiles['text'] = profiles.apply(concat, axis=1, cols=essay_cols)\n",
    "profiles['edu'] = profiles.education.apply(recode, dictionary=ed_levels, \n",
    "                                            default='unknown')\n",
    "profiles['kids'] = profiles.offspring.apply(recode_fuzzy, dictionary=kids, \n",
    "                                            default='no')\n",
    "profiles['pets_likes'] = profiles.pets.apply(which_pets, criterion='likes')\n",
    "profiles['pets_has'] = profiles.pets.apply(which_pets, criterion='has')\n",
    "profiles['pets_any'] = profiles.pets.apply(recode_fuzzy, dictionary=has_pets, \n",
    "                                            default='no')\n",
    "profiles['age_group'] = profiles.age.apply(lambda x: str(int(x/10)*10))\n",
    "profiles['height_group'] = profiles.height.apply(height)\n",
    "profiles['race_ethnicity'] = profiles.ethnicity.apply(census_2010_ethnicity)\n",
    "profiles['smoker'] = profiles.smokes.apply(recode, dictionary=smoke, \n",
    "                                            default='yes')\n",
    "profiles['body'] = profiles.body_type.apply(recode, dictionary=bodies, \n",
    "                                            default='unknown')\n",
    "profiles['alcohol_use'] = profiles.drinks.apply(recode, dictionary=drinks, \n",
    "                                            default='yes')\n",
    "profiles['drug_use'] = profiles.drugs.apply(recode, dictionary=drugs, \n",
    "                                            default='yes')\n",
    "profiles['industry'] = profiles.job.apply(recode_fuzzy, dictionary=jobs, \n",
    "                                            default='other')\n",
    "profiles['religion'] = profiles.religion.apply(recode_fuzzy, dictionary=religion, \n",
    "                                            default='other')\n",
    "profiles['languages'] = profiles.speaks.apply(recode_fuzzy, dictionary=languages, \n",
    "                                            default='English_only')\n",
    "\n",
    "# keep just these columns\n",
    "profiles = profiles[['age_group', 'age', 'body', 'alcohol_use', 'drug_use', 'edu', \n",
    "                     'race_ethnicity', 'height_group', 'industry', 'kids', \n",
    "                     'orientation', 'pets_likes', 'pets_has', 'pets_any', \n",
    "                     'religion', 'sex', 'smoker', 'languages', 'text', 'essay0', \n",
    "                     'essay1', 'essay2', 'essay3', 'essay4', 'essay5', 'essay6', \n",
    "                     'essay7', 'essay8', 'essay9']]\n",
    "\n",
    "profiles.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the results\n",
    "This cell saves the cleaned up data to a file so we can use it again later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles.to_csv('data/clean_profiles.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For laptop or personal computer users\n",
    "Run this code so that you're working with a smaller amount of data and don't crash your computer. It takes a simple random sample of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles = profiles.sample(20000)\n",
    "profiles = profiles.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### While we're at it, let's make some helper functions for later.\n",
    "Run this code, but don't worry about these now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_example(text, word, context=False):\n",
    "    #regex for selecting the whole word from a stem\n",
    "    expr = word + '\\w*'\n",
    "    \n",
    "    if context:\n",
    "        #regex for selecting a stem and also the 2 words before and after it\n",
    "        #this lets us see the context in which it is used\n",
    "        expr = '\\w*\\W*\\w*\\W*' + word + '\\w*\\W*\\w*\\W*\\w*'\n",
    "\n",
    "    return re.search(expr, text, re.I).group()\n",
    "\n",
    "def get_examples(data, word, n=5, context=True, limit_col=None, limit_val=None):\n",
    "    if word.endswith('i'):\n",
    "        #the Porter2 stemmer sometimes adds 'i' to stems. This trimms it off.\n",
    "        word = word[:-1]\n",
    "    \n",
    "    #restrict to just some group of interest\n",
    "    if limit_col is not None:\n",
    "        data = data[data[limit_col] == limit_val]\n",
    "    \n",
    "    #sample our data so this operation goes faster\n",
    "    if data.shape[0] > 1000:\n",
    "        data = data.sample(1000)\n",
    "    \n",
    "    #find profiles with the word in them\n",
    "    tmp = data.text.apply(lambda x: word in x)\n",
    "    #select n random profiles that have the word\n",
    "    count = tmp.sum()\n",
    "    \n",
    "    #if we wanted more examples than there are\n",
    "    if n > count:\n",
    "        n = count\n",
    "    tmp2 = data[tmp].text.sample(n).values\n",
    "    \n",
    "    #get an example out of each profile we selected\n",
    "    tmp = []\n",
    "    for t in tmp2:\n",
    "        tmp.append(extract_example(t, word, context))\n",
    "    \n",
    "    return tmp\n",
    "\n",
    "def unstem(word, data, n=50):\n",
    "    if word.endswith('i'):\n",
    "        #the Porter2 stemmer sometimes adds 'i' to stems. This trimms it off.\n",
    "        word = word[:-1]\n",
    "\n",
    "    #use the function we made before to get examples of the stem\n",
    "    tmp = get_examples(data, word=word, n=n, context=False)\n",
    "    \n",
    "    #count up and return the most common form of the word matching the stem\n",
    "    return Counter(tmp).most_common(1)[0][0]\n",
    "\n",
    "def clean_index(df, text):\n",
    "    #replaces stems in the index of a dataframe with whole words\n",
    "    df.reset_index(inplace=True)\n",
    "    df['index'] = df['index'].apply(unstem, data=text)\n",
    "    df.set_index('index', inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Tokenizing text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's peak at an example of the text so we know what we're working with.\n",
    "This code shows us the text for the 6th profile (python counts from 0, so the first profile is #0, the second is #1, and so on). 5 here could be any number. Try changing it to see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles.text[6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We want to split the text into words so we can count them. Here's a simple first try.\n",
    "- The `split()` function, like its name suggests, splits text into chunks. If we split on spaces (the default), it will split the text into words. Let's `apply` it to the `text` of our `profiles`.\n",
    "- Notice that this is a little messy. The punctuation and some HTML things are mixed in with our words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = profiles['text'].apply(lambda x: x.split())\n",
    "tmp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A better way of getting words from text\n",
    "### Steps\n",
    "#### 1. Removing stop words\n",
    "- \"Stop words\" are words that are common in a language but don't tell us much about what's happening, like \"a,\" \"of,\" or \"and.\" It is common to remove them so we can focus on more meaningful words. [Learn more](https://en.wikipedia.org/wiki/Stop_words)\n",
    "- Here we use the set of English stop words we imported above.\n",
    "- This lab makes an exception to the normal list of stop words and keeps the pronouns because some research shows that pronoun use matters in dating. You could add more words to remove or keep, depending on what you think is important. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = set(stopwords.words('english'))\n",
    "\n",
    "keep_words = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \n",
    "              'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', \n",
    "              'himself', 'she', 'her', 'hers', 'herself', 'they', 'them', 'their',\n",
    "              'theirs', 'themselves']\n",
    "\n",
    "for k in keep_words:\n",
    "    sw.discard(k) #could use remove if we wanted keyerrors\n",
    "    \n",
    "print(\"Here are the words we will remove:\\n\\n\", sw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Better tokenizing\n",
    "- This code actually cleans the text. \n",
    "    - We use the BeautifulSoup library to remove all the HTML code from the text\n",
    "    - We also remove some other non-word text like \"www\"\n",
    "    - We convert all the text to lowercase, so that the computer sees \"Dogs\", \"DOGS\", and \"dogs\" as the same word.\n",
    "    - We remove all the stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text, sw):\n",
    "    t = BeautifulSoup(text, 'lxml').get_text()\n",
    "    \n",
    "    bad_words = ['http', 'www', '\\nnan']\n",
    "    for b in bad_words:\n",
    "        t = t.replace(b, '')\n",
    "    \n",
    "    t = t.lower()\n",
    "    t = regexp_tokenize(t, '\\w+')\n",
    "    \n",
    "    final = []\n",
    "    for w in t:\n",
    "        if w not in sw:\n",
    "            final.append(w)\n",
    "    \n",
    "    return final\n",
    "\n",
    "profiles['tokens'] = profiles['text'].apply(clean, sw=sw)\n",
    "profiles.tokens.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 2. Comparing the words used by men and women\n",
    "#### Step 1: We separate the profiles of women and men.\n",
    "We'll limit it to straight people for now. You'll have the chance to explore other groups later in the lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "men = profiles[(profiles['sex'] == 'm') & (profiles['orientation'] == 'straight')]\n",
    "women = profiles[(profiles['sex'] == 'f') & (profiles['orientation'] == 'straight')]\n",
    "\n",
    "men.tokens.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Counting how often each gender uses each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(series):\n",
    "    l = []\n",
    "    for x in series:\n",
    "        l.extend(x) #each x is a list we want to unnest\n",
    "    return l\n",
    "\n",
    "#\"tmp\" is often used for temporary or intermediate data that we won't use for long.\n",
    "tmp = flatten(men.tokens)\n",
    "\n",
    "print('Ten most common words used by men:')\n",
    "mens_words = Counter(tmp) #this counts how many times each word shows up\n",
    "mens_words.most_common(10) #this shows us the 10 most common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = flatten(women.tokens) #repeat for women\n",
    "\n",
    "print('Ten most common words used by women:')\n",
    "womens_words = Counter(tmp)\n",
    "womens_words.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the most popular words are basically the same for each gender.\n",
    "\n",
    "#### Step 3a: Put the word counts in a data frame so they're easier to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn the two word count data into a single dataframe so it's easy to work with \n",
    "tmp = {'women': womens_words, 'men': mens_words}\n",
    "popular_words = pd.DataFrame(tmp)\n",
    "\n",
    "popular_words.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right now, the words are sorted alphabetically. That's not super useful, though.\n",
    "\n",
    "#### Step 3b: Sort the words by popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_words = popular_words.sort_values(by='women', ascending=False)\n",
    "popular_words.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Convert those word counts to frequencies (percent of total words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the word counts into percents (i.e. what percent of total words are x)\n",
    "popular_words['men'] = (popular_words['men'] /  popular_words['men'].sum())*100\n",
    "popular_words['women'] = (popular_words['women'] /  popular_words['women'].sum())*100\n",
    "\n",
    "#create a column \"max\" that has the word's maxmum popularity (in either men or women)\n",
    "popular_words['max'] = popular_words.max(axis=1)\n",
    "\n",
    "#show the most popular words overall\n",
    "popular_words.sort_values(by='max', ascending=False, inplace=True)\n",
    "popular_words.head(10).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's see some typical examples of how these words are used\n",
    "- You can change the number `6` to show more or less examples.\n",
    "- You can change the world `'love'` to any word you're interested in. \n",
    "    - \"love\" is interesting because it is not always used the way we might expect in a dating profile. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_examples(data=profiles, word='love', n=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's look just at examples of how men use the word 'love'\n",
    "- You can change `limit_col` to something other than `sex` if you want to look at a different attribute.\n",
    "- You can change `limit_val` to something other than `m` if you want to look at a different group within the attribute (e.g. change it to `f` if you want to see women's use)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_examples(data=profiles, word='love', n=6, limit_col='sex', limit_val='f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Most words are very uncommon\n",
    "- The X axis in this histogram is the word popularity (percent of total words that are this word). \n",
    "- The Y axis is the number of words that have that level of popularity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show a histogram with 100 bins\n",
    "popular_words['max'].plot.hist(bins=100, log=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Look at just the 1000 most popular words\n",
    "- Note that the shape of the distribution looks similar, but the Y axis is much smaller ($ 10^3 $ instead of $ 10^5 $), meaning we have removed many extremely uncommon words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select only the 1000 most popular words\n",
    "popular_words = popular_words.sort_values(by='max', ascending=False).head(1000)\n",
    "\n",
    "#show the histogram again\n",
    "popular_words['max'].plot.hist(bins=100, log=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Figure out which words are more popular with one gender than the other\n",
    "- Here we calculate how many times different the usage of words by men or women is, so if men use a word twice as often as women use the same word, then then men's use is 2 times different. \n",
    "- Like we saw before, both groups use the most popular words about the same amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def times_diff(row):\n",
    "    #calculate how many times more men use a word than women\n",
    "    #or vice versa if women use the word more\n",
    "    if row.men > row.women:\n",
    "        return row.men / row.women\n",
    "    else:\n",
    "        return -1 * (row.women / row.men)\n",
    "    \n",
    "popular_words['times_diff'] = popular_words.apply(times_diff, axis=1)\n",
    "popular_words = popular_words.sort_values(by='max', ascending=False)\n",
    "\n",
    "print('Most popular words:')\n",
    "popular_words.head(10).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's look at the words that are most different between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Words men use more than women:')\n",
    "popular_words.sort_values(by='times_diff', ascending=False).head(15).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Words women use more than men:')\n",
    "popular_words.sort_values(by='times_diff', ascending=True).head(15).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Getting cleaner results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stemming lets us count similar words like \"dog\" and \"dogs\" or \" run\" and \"running\" as the same word.\n",
    "- Stemming grabs just the \"stem\" of each word (e.g. the stem of both \"runs\" and \"running\" is \"run\"). When the words are converted to their stems, the computer sees them as the same. [Learn more](https://en.wikipedia.org/wiki/Stemming)\n",
    "- Stemming can be a little slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#snowball English (aka porter2) is the best general stemmer\n",
    "stemmer = SnowballStemmer(\"english\") \n",
    "\n",
    "def stem(t):\n",
    "    out = []\n",
    "    for w in t:\n",
    "        out.append(stemmer.stem(w))\n",
    "    return out\n",
    "\n",
    "print(\"Stemming words from profile text...\")\n",
    "profiles['stems'] = profiles['tokens'].apply(stem)\n",
    "profiles.stems.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### These functions let us do the same things we did before without rewriting all the steps each time.\n",
    "You don't have to worry about what's in them right now. Just run the cell and scroll down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for summarizing word use by a trait\n",
    "def times_diff2(row, group, ref):\n",
    "    if row[ref] > row[group]:\n",
    "        return -1 * (row[ref] / row[group])\n",
    "    else:\n",
    "        return row[group] / row[ref]\n",
    "\n",
    "#normally we wouldn't paste this function here because we already have it above\n",
    "#but it helps to show in the lab\n",
    "def flatten(series):\n",
    "    l = []\n",
    "    for x in series:\n",
    "        l.extend(x) #each x is a list we want to unnest\n",
    "    return l\n",
    "    \n",
    "def flatten2(series):\n",
    "    l = []\n",
    "    for x in series:\n",
    "        tmp = set(x) #make the tokens into a set, thus dropping repeats\n",
    "        tmp = list(tmp) #turn it back into a list we can attach to the other lists\n",
    "        l.extend(tmp) \n",
    "    return l\n",
    "\n",
    "\n",
    "def count(data, per_person):\n",
    "    #count the people in each category\n",
    "    l = len(data)\n",
    "\n",
    "    #apply the right aggregation function, depending whether we want \n",
    "    #most common words, or words used by most people\n",
    "    if per_person:\n",
    "        data = flatten2(data)\n",
    "    else:\n",
    "        data = flatten(data)\n",
    "            \n",
    "    c = Counter(data)\n",
    "    \n",
    "    return c, l\n",
    "\n",
    "def word_use(df, att, ref=None, per_person=False, undostems=False):\n",
    "    #list all of the categories in this column\n",
    "    types = list(df[att].value_counts().index.values)\n",
    "    #variables that will store our results\n",
    "    data = {}\n",
    "    lens = {}\n",
    "    \n",
    "    print(\"Counting the words used by each group...\")\n",
    "    for t in types:\n",
    "        #get the stems for each category\n",
    "        tmp = df[df[att] == t].stems\n",
    "        #count how often each is used\n",
    "        data[t], lens[t] = count(tmp, per_person)\n",
    "        \n",
    "        #also compute the inverse of each category\n",
    "        tmp = df[df[att] != t].stems\n",
    "        data['not_'+str(t)], lens['not_'+str(t)] = count(tmp, per_person)        \n",
    "        \n",
    "    #convert those results to a pandas data frame for easy handling\n",
    "    popular_words = pd.DataFrame(data)\n",
    "    \n",
    "    print('Calculating percentages...')\n",
    "    # convert the counts in each column to percents\n",
    "    for t in popular_words.columns:\n",
    "        n = lens[t] #if we want percent of people\n",
    "        \n",
    "        if not per_person: #if we want percent of total words \n",
    "            n = popular_words[t].sum()\n",
    "        \n",
    "        popular_words[t] = (popular_words[t] / n) * 100\n",
    "    \n",
    "    print('Selecting the most popular words...')\n",
    "    #find overall most popular words\n",
    "    popular_words['max'] = popular_words.max(axis=1)\n",
    "    #sort the words and select the top 1000 most popular\n",
    "    popular_words = popular_words.sort_values(by='max', ascending=False)\n",
    "    popular_words = popular_words.head(1000)\n",
    "\n",
    "    print('Calculating most distinctive words...')\n",
    "    #calculate the rate each type of person uses these words relative to others\n",
    "    for t in types:\n",
    "        r = ref\n",
    "        \n",
    "        if ref == None: #if we do not have a reference category, use the inverse\n",
    "            r = 'not_'+str(t)\n",
    "            \n",
    "        if t != ref: #don't compare a trait to itself\n",
    "            #apply our times_diff2 function\n",
    "            popular_words['times_diff_'+str(t)] = popular_words.apply(times_diff2, \n",
    "                                                                 group=t, \n",
    "                                                                 ref=r, \n",
    "                                                                 axis=1)\n",
    "\n",
    "    #remove the inverse columns we created\n",
    "    popular_words = popular_words.drop(popular_words.filter(regex='not_'), axis=1)\n",
    "    \n",
    "    if undostems:\n",
    "        print('Cleaning up word stems for readability...')\n",
    "        popular_words = clean_index(popular_words, df)\n",
    "    \n",
    "    print('Done!')\n",
    "    return popular_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's try comparing men's and women's words again with stems this time\n",
    "- The top words are somewhat different now that we're counting similar words as the same.\n",
    "- We see word stems rather than whole words listed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_words = word_use(profiles, att='sex')\n",
    "popular_words = popular_words.sort_values(by='times_diff_m', ascending=False)\n",
    "print(\"Men's words:\")\n",
    "popular_words.head(10).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Those word stems in our table are a little hard to read. Let's change that.\n",
    "- The `undostems=True` option converts the stems back to whole words before showing us the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_words = word_use(profiles, att='sex', undostems=True)\n",
    "popular_words = popular_words.sort_values(by='times_diff_m', ascending=False)\n",
    "print(\"Men's distinctive words:\")\n",
    "popular_words.head(10).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_words = popular_words.sort_values(by='times_diff_f', ascending=False)\n",
    "print(\"Women's distinctive words:\")\n",
    "popular_words.head(10).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### But, wait! Not all profiles have the same number of words. \n",
    "- What if a single man just wrote \"computer\" a thousand times and that is skewing our results?\n",
    "- With `per_person=True` we can see which words are used by the most different people, rather than which words are most common out of all the words used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_words = word_use(profiles, att='sex', per_person=True, undostems=True)\n",
    "print(\"Men's words:\")\n",
    "popular_words.sort_values(by='times_diff_m', ascending=False).head(10).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Women's words:\")\n",
    "popular_words.sort_values(by='times_diff_f', ascending=False).head(10).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 4. Your turn to try it with another trait"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Options (traits)\n",
    "We have a lot more information about people than just whether they're men or women. Try the analysis again with one of these other traits. (Expand for a list.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- age_group (How old someone is. Youngest users are 18.)\n",
    "    - categories: ['10', '20', '30', '40', '50']\n",
    "- body (self-described)\n",
    "    - categories: ['average', 'fit', 'thin', 'overweight', 'unknown']\n",
    "- alcohol_use\n",
    "    - categories: ['yes', 'no']\n",
    "- drug_use\n",
    "    - categories: ['yes', 'no']\n",
    "- edu (highest degree completed)\n",
    "    - categories: ['`<HS`', 'HS', 'BA', 'Grad_Pro', 'unknown'] \n",
    "- race_ethnicity\n",
    "    - categories: ['Asian', 'Black', 'Latinx', 'White', 'multiple', 'other']\n",
    "- height_group (whether someone is over or under six feet tall)\n",
    "    - categories: ['under_6', 'over_6']\n",
    "- industry (what field they work in)\n",
    "    - categories: ['STEM', 'business', 'education', 'creative', 'med_law', 'other'] \n",
    "- kids (whether they have children)\n",
    "    - categories: ['yes', 'no']\n",
    "- orientation\n",
    "    - categories: ['straight', 'gay', 'bisexual']\n",
    "- pets_likes (what pets they like)\n",
    "    - categories: ['both', 'dogs', 'cats', 'neither']\n",
    "- pets_has (what pets they have)\n",
    "    - categories: ['both', 'dogs', 'cats', 'neither']\n",
    "- pets_any (whether they have pets or not)\n",
    "    - categories: ['yes', 'no']\n",
    "- religion\n",
    "    - categories: ['christianity', 'catholicism', 'judaism', 'buddhism', 'none', 'other'] \n",
    "- sex\n",
    "    - categories: ['m', 'f']\n",
    "- smoker\n",
    "    - categories: ['yes', 'no']\n",
    "- languages\n",
    "    - categories: ['multiple', 'English_only'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to (steps)\n",
    "#### Step 1a: Decide which of the traits above you want to look at.\n",
    "#### Step 1b: Load the profile data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles = pd.read_csv('data/clean_profiles.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Step 2a: If you want, limit the data to just men or women.\n",
    "- For everyone, leave this code how it is.\n",
    "- For only men, remove the `#`\n",
    "- For only women, remove the `#` and change the `'m'` in this line to `'f'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#profiles = profiles[profiles['sex'] == 'm']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2b: If you're running this on your personal computer\n",
    "Run this code to use just a sample of the data set, because the full data is big enough to crash most personal computers. You can make the sample bigger or smaller by changing the number here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles = profiles.sample(20000)\n",
    "profiles.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Tokenize and stem the text for these profiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tokenizing...\")\n",
    "profiles['tokens'] = profiles['text'].apply(clean, sw=sw)\n",
    "print(\"Stemming...\")\n",
    "profiles['stems'] = profiles['tokens'].apply(stem)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Compute the word usage statistics for your chosen attribute.\n",
    "You can change the code below:\n",
    "- You can change `att='age_group'` to your attribute of interest (e.g. `pets_likes` or `orientation`)\n",
    "- The `per_person` and `undostems` are the same as we saw before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = word_use(profiles, att='age_group', per_person=True, undostems=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5a: Look at the results.\n",
    "First, let's just see what columns we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.head(2).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5b: Looking at the most distinctive words by category\n",
    "You can change two things in this code:\n",
    "1. Change `'times_diff_10'` to the name of the column you want to sort by, i.e. the column you want to see the most popular words in. \n",
    "2. Change the number in `head(10)` to a bigger or smaller number to see more or less rows of output.\n",
    "\n",
    "You can paste this line into more cells below and change it again to show different groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.sort_values(by='times_diff_10', ascending=False).head(10).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.sort_values(by='times_diff_20', ascending=False).head(10).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.sort_values(by='times_diff_30', ascending=False).head(10).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.sort_values(by='times_diff_40', ascending=False).head(10).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.sort_values(by='times_diff_50', ascending=False).head(10).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. What we learned\n",
    "Expand for more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Sociology & Gender\n",
    "1. Overall, the most common words in online dating are the same for men and women in San Fransisco. What they say about themselves is not that different. \n",
    "2. There are some words that men use much more often than women, and vice versa. These fit stereotypical gender roles: for example, men in San Fransisco are much more likely to talk about computers, startups, engineering, and sports. And women are much more likely to talk about food (e.g. baking and chocolate) or feelings (adore, laughter). \n",
    "3. There are many possible causes for these differences in word use. For example, it is often taboo for men to talk about their feelings, so they may mention them less here because of social expectations rather than because they are less emotional. Social factors can also increase expression: for instance, women typically do the majority of food preparation in American families, so it is not surprising that they are more likely than men to talk about it in dating profiles. \n",
    "4. Not every person conforms to these broad patterns. Only 10-20% of these men mention computers. A similar percent of the women mention baking. Some women talk about computers, and some men talk about baking. Most people aren't using these very gendered words at all. What we showed is that there are broad patterns of some topics being much more popular with men or women, and that these patterns line up with common cultural expectations of gender."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Text analysis\n",
    "1. **Tokenizing** is the process of splitting text into words (tokens). Simple approaches can separate words based on spaces, but punctuation, HTML, and other things can make this more complicated. \n",
    "2. **Stop words** are words that are common but don't give us much information. They're often removed before we do analysis.\n",
    "3. **Stemming** lets us combine similar words like \"runs\" and \"running\" by looking at the stem of the words (in this case, \"run\"). \n",
    "4. Most words are not very common. [Oxford Dictionaries](https://en.oxforddictionaries.com/explore/how-many-words-are-there-in-the-english-language) lists over 171,000 currently used English words, but as we saw, only a few words show up in more than a few profiles. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
