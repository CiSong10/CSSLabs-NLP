{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What's in an online dating profile? \n",
    "\n",
    "People say a lot about themselves in online dating profiles, especially on sites like OKCupid that encourage people to answer questions. Thus, we can learn a lot about people by studying what they write. OKC has made some of their profile data from San Fransisco public. We will be using that data in this lab to explore different cultural questions. \n",
    "\n",
    "Our first question is whether and how men and women talk about themselves differently in their profiles. Popular culture is constantly telling us that men and women have different interests, hobbies, and relationship goals. Yet there are also many examples of women who like stereotypically masculine things and men who like feminine ones. This is especially interesting in online dating, because people are seeking partners with similar interests and relationship goals. Finding a partner would be hard for straight men and women if these two groups had very different interests. \n",
    "\n",
    "OKC shared 59,946 profiles though -- way too many to read! Computers can read them all and tell us how common different words are. So our first approach will be simple. We can ask \n",
    "1. Which words are used the most by men and women? \n",
    "2. Which words are used often by men but not women, and vice versa? \n",
    "\n",
    "At the end of the lab, you'll be able to ask this question about other social groups too (like sexual orientation, race/ethnicity, and level of education)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the libraries we'll use.\n",
    "`%matplotlib inline` lets us see charts and plots right here in the notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import regexp_tokenize \n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "profiles = pd.read_csv('data/profiles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove people 60+ and 17-\n",
    "profiles = profiles[(profiles.age < 60) & (profiles.age > 17)]\n",
    "\n",
    "#random subsample so this doesn't crash on laptops\n",
    "profiles = profiles.sample(20000)\n",
    "profiles = profiles.reset_index(drop=True)\n",
    "profiles.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### A little housekeeping...\n",
    "Expand for more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- The OKC data has 10 different columns with profile text, one for each long-answer question in users' profiles.\n",
    "- We want to look at all of the profile text, so this cell merges it all together in a new column called `text`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "essay_cols = ['essay0', 'essay1', 'essay2', 'essay3', 'essay4', 'essay5', 'essay6', \n",
    "              'essay7', 'essay8', 'essay9']\n",
    "\n",
    "ed_levels = {'<HS': ['dropped out of high school', 'working on high school'],\n",
    "             'HS': ['graduated from high school', 'working on college/university', \n",
    "                    'two-year college', 'dropped out of college/university', \n",
    "                    'high school'], \n",
    "             'BA': ['graduated from college/university', \n",
    "                    'working on masters program', 'working on ph.d program', \n",
    "                    'college/university', 'working on law school', \n",
    "                    'dropped out of masters program', \n",
    "                    'dropped out of ph.d program', 'dropped out of law school', \n",
    "                    'dropped out of med school'],\n",
    "             'Grad_Pro': ['graduated from masters program',\n",
    "                          'graduated from ph.d program',                           \n",
    "                          'graduated from law school', \n",
    "                          'graduated from med school', 'masters program', \n",
    "                          'ph.d program', 'law school', 'med school']\n",
    "            }\n",
    "\n",
    "bodies = {'average': ['average'], \n",
    "          'fit': ['fit', 'athletic', 'jacked'], \n",
    "          'thin': ['thin', 'skinny'], \n",
    "          'overweight': ['curvey', 'a little extra', 'full figured', 'overweight']\n",
    "         }\n",
    "\n",
    "smoke = {'no': ['no'], np.nan: ['nan']}\n",
    "\n",
    "kids = {'yes': ['has a kid', 'has kids']}\n",
    "\n",
    "has_pets = {'yes': ['has']}\n",
    "\n",
    "ethn = {'White': ['white', 'middle eastern', 'middle eastern, white'], \n",
    "        'Asian': ['asian', 'indian', 'asian, pacific islander'], \n",
    "        'Black': ['black']\n",
    "       }   \n",
    "\n",
    "ethn2 = {'Latinx': ['latin'], 'multiple': [','], np.nan: ['nan']}   \n",
    "\n",
    "drinks = {'no': ['rarely', 'not at all']}\n",
    "\n",
    "drugs = {'no': ['never']}\n",
    "\n",
    "jobs = {'education': ['student', 'education'], \n",
    "        'STEM': ['science', 'computer'], \n",
    "        'business': ['sales', 'executive', 'banking'], \n",
    "        'creative': ['artistic', 'entertainment'], \n",
    "        'med_law': ['medicine', 'law'],\n",
    "        np.nan: ['nan']\n",
    "       }\n",
    "\n",
    "religion = {'none': ['agnosticism', 'atheism'],\n",
    "            'catholicism': ['catholicism'],\n",
    "            'christianity': ['christianity'],\n",
    "            'judaism': ['judaism'],\n",
    "            'buddhism': ['buddhism'],\n",
    "            np.nan: ['nan']\n",
    "           }\n",
    "\n",
    "languages = {'multiple': [',']}\n",
    "\n",
    "\n",
    "def concat(row, cols):\n",
    "    tmp = []\n",
    "    for c in cols:\n",
    "        tmp.append(str(row[c]))\n",
    "    new = '\\n'.join(tmp)\n",
    "    return new\n",
    "\n",
    "def recode(text, dictionary, default=np.nan):\n",
    "    out = default\n",
    "    text = str(text)\n",
    "    \n",
    "    for x in dictionary.keys():\n",
    "        for y in dictionary[x]:\n",
    "            if y == text:\n",
    "                out = x\n",
    "                return out\n",
    "    return out\n",
    "\n",
    "def recode_fuzzy(text, dictionary, default=np.nan):\n",
    "    out = default\n",
    "    text = str(text)\n",
    "    \n",
    "    for x in dictionary.keys():\n",
    "        for y in dictionary[x]:\n",
    "            if y in text:\n",
    "                out = x\n",
    "                return out\n",
    "    return out\n",
    "\n",
    "\n",
    "def which_pets(t, criterion='has'):\n",
    "    d = False\n",
    "    c = False\n",
    "    t = str(t)\n",
    "    p = 'neither'\n",
    "    if t == 'nan':\n",
    "        p = np.nan\n",
    "    \n",
    "    if 'has dogs' in t:\n",
    "        d = True\n",
    "    if 'has cats' in t:\n",
    "        c = True\n",
    "        \n",
    "    if criterion == 'likes':\n",
    "        if 'likes dogs' in t:\n",
    "            if 'dislikes dogs' not in t:\n",
    "                d = True\n",
    "        if 'likes cats' in t:\n",
    "            if 'dislikes cats' not in t:\n",
    "                c = True\n",
    "        \n",
    "    if c and d:\n",
    "        p = 'both'\n",
    "    elif c:\n",
    "        p = 'cats'\n",
    "    elif d:\n",
    "        p = 'dogs'\n",
    "        \n",
    "    return p\n",
    "\n",
    "def census_2010_ethnicity(t):\n",
    "    '''\n",
    "    Function gathers choices for this question gathered by the US Census 2010.\n",
    "    It deviates from the census by creating exclusive Latinx category. Selecting \n",
    "    just 'latin' and nothing else was the 3rd most frequent ethnicity in this \n",
    "    data. The discision to include people who identified 'latin' and another race\n",
    "    is based in research on Latinx people's experience with the US Census, but \n",
    "    like all racial and ethnic categorization systems it is flawed. \n",
    "    '''\n",
    "    text = str(t)\n",
    "    \n",
    "    e = recode(text, ethn, default='other')\n",
    "    if 'other' == e:\n",
    "        e = recode_fuzzy(text, ethn2, default='other')\n",
    "    \n",
    "    return e\n",
    "\n",
    "def height(inches):\n",
    "    h = 'under_6'\n",
    "    if inches >= 72:\n",
    "        h = 'over_6'\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles['text'] = profiles.apply(concat, axis=1, cols=essay_cols)\n",
    "profiles['edu'] = profiles.education.apply(recode, dictionary=ed_levels, \n",
    "                                            default='unknown')\n",
    "profiles['kids'] = profiles.offspring.apply(recode_fuzzy, dictionary=kids, \n",
    "                                            default='no')\n",
    "profiles['pets_likes'] = profiles.pets.apply(which_pets, criterion='likes')\n",
    "profiles['pets_has'] = profiles.pets.apply(which_pets, criterion='has')\n",
    "profiles['pets_any'] = profiles.pets.apply(recode_fuzzy, dictionary=has_pets, \n",
    "                                            default='no')\n",
    "profiles['age_group'] = profiles.age.apply(lambda x: str(int(x/10)*10))\n",
    "profiles['height_group'] = profiles.height.apply(height)\n",
    "profiles['race_ethnicity'] = profiles.ethnicity.apply(census_2010_ethnicity)\n",
    "profiles['smoker'] = profiles.smokes.apply(recode, dictionary=smoke, \n",
    "                                            default='yes')\n",
    "profiles['body'] = profiles.body_type.apply(recode, dictionary=bodies, \n",
    "                                            default='unknown')\n",
    "profiles['alcohol_use'] = profiles.drinks.apply(recode, dictionary=drinks, \n",
    "                                            default='yes')\n",
    "profiles['drug_use'] = profiles.drugs.apply(recode, dictionary=drugs, \n",
    "                                            default='yes')\n",
    "profiles['industry'] = profiles.job.apply(recode_fuzzy, dictionary=jobs, \n",
    "                                            default='other')\n",
    "profiles['religion'] = profiles.religion.apply(recode_fuzzy, dictionary=religion, \n",
    "                                            default='other')\n",
    "profiles['languages'] = profiles.speaks.apply(recode_fuzzy, dictionary=languages, \n",
    "                                            default='English_only')\n",
    "\n",
    "profiles = profiles[['age_group', 'body', 'alcohol_use', 'drug_use', 'edu', \n",
    "                     'race_ethnicity', 'height_group', 'industry', 'kids', \n",
    "                     'orientation', 'pets_likes', 'pets_has', 'pets_any', \n",
    "                     'religion', 'sex', 'smoker', 'languages', 'text']]\n",
    "profiles.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's peak at an example of the text so we know what we're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "profiles.text[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### We want to split the text into words.\n",
    "Expand for details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- We can do this by applying the `split()` function to text in every profile. \n",
    "- Notice, however, that this is a little messy.\n",
    "    - `split()` is just cutting up the text based on the spaces, leaving the punctuation and some HTML things mized in with our words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A first try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp = profiles['text'].apply(lambda x: x.split())\n",
    "tmp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting text from words\n",
    "Expand for details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define a function to clean up the text a bit more. It does a few things:\n",
    "- Removes HTML code from the text using BeautifulSoup. (Remember, we want just the words people actually typed.) \n",
    "- Converts all of the text to lowercase, so that `Hello`, `hello`, `\"HeLlO`, and `HELLO` all look the same to the computer.\n",
    "- Uses the Natural Language Tool Kit (`nltk`) to tokenize the remaining text. \n",
    "    - \"Tokenize\" is jargon for splitting text into \"tokens.\" Tokens are usually words, but they could be sentences, paragraphs, letters, or whatever we needed. \n",
    "    - The nltk tokenizers are much smarter than the simple `string.split()` function we used before. This one (which we imported in the beginning) selects the words, but ignores the whitespace and punctuation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A second try"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keep_words = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \n",
    "              'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', \n",
    "              'himself', 'she', 'her', 'hers', 'herself', 'they', 'them', 'their',\n",
    "              'theirs', 'themselves']\n",
    "\n",
    "sw = set(stopwords.words('english'))\n",
    "\n",
    "for k in keep_words:\n",
    "    sw.discard(k) #could use remove if we wanted keyerrors\n",
    "    \n",
    "print(sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    t = BeautifulSoup(text, 'lxml').get_text()\n",
    "    \n",
    "    bad_words = ['http', 'www', '\\nnan']\n",
    "    for b in bad_words:\n",
    "        t = t.replace(b, '')\n",
    "    \n",
    "    t = t.lower()\n",
    "    t = regexp_tokenize(t, '\\w+')\n",
    "    \n",
    "    final = []\n",
    "    for w in t:\n",
    "        if w not in sw:\n",
    "            final.append(w)\n",
    "    \n",
    "    return final\n",
    "\n",
    "profiles['tokens'] = profiles['text'].apply(clean)\n",
    "profiles.tokens.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Comparing the words used by men and women"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "men = profiles[(profiles['sex'] == 'm') & (profiles['orientation'] == 'straight')]\n",
    "women = profiles[(profiles['sex'] == 'f') & (profiles['orientation'] == 'straight')]\n",
    "\n",
    "men.tokens.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Counting how often each gender uses each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flatten(series):\n",
    "    l = []\n",
    "    for x in series:\n",
    "        l.extend(x) #each x is a list we want to unnest\n",
    "    return l\n",
    "\n",
    "tmp = flatten(men.tokens)\n",
    "\n",
    "mens_words = Counter(tmp)\n",
    "mens_words.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp = flatten(women.tokens)\n",
    "\n",
    "womens_words = Counter(tmp)\n",
    "womens_words.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert those word counts to frequencies (percent of total words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp = {'women': womens_words,\n",
    "       'men': mens_words\n",
    "      }\n",
    "\n",
    "popular_words = pd.DataFrame(tmp)\n",
    "\n",
    "popular_words['men'] = (popular_words['men'] /  popular_words['men'].sum())*100\n",
    "popular_words['women'] = (popular_words['women'] /  popular_words['women'].sum())*100\n",
    "\n",
    "popular_words.sort_values(by='men', inplace=True, ascending=False)\n",
    "popular_words.head().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "popular_words['max'] = popular_words.max(axis=1)\n",
    "popular_words = popular_words.sort_values(by='max', ascending=False)\n",
    "popular_words.head(10).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### See the distribution of word popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "popular_words['max'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look at just the 1000 most popular words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "popular_words = popular_words.head(1000)\n",
    "print(popular_words.shape)\n",
    "popular_words['max'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure out which words are popular with one gender but not the other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def times_diff(row):\n",
    "    if row.men > row.women:\n",
    "        return row.men / row.women\n",
    "    else:\n",
    "        return -1 * (row.women / row.men)\n",
    "    \n",
    "popular_words['times_diff'] = popular_words.apply(times_diff, axis=1)\n",
    "popular_words = popular_words.sort_values(by='max', ascending=False)\n",
    "\n",
    "print('Most popular words:')\n",
    "popular_words.head(10).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "popular_words = popular_words.sort_values(by='times_diff', ascending=False)\n",
    "\n",
    "print('Words men use more than women:')\n",
    "popular_words.head(15).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "popular_words = popular_words.sort_values(by='times_diff', ascending=True)\n",
    "\n",
    "print('Words women use more than men:')\n",
    "popular_words.head(15).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#snowball English (aka porter2) is improved over the porter stemmer\n",
    "stemmer = SnowballStemmer(\"english\") \n",
    "\n",
    "def stem(t):\n",
    "    out = []\n",
    "    for w in t:\n",
    "        out.append(stemmer.stem(w))\n",
    "    return out\n",
    "\n",
    "profiles['stems'] = profiles['tokens'].apply(stem)\n",
    "profiles.stems.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's try it again with stems this time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# functions for summarizing word use by a trait\n",
    "def times_diff2(row, group, ref):\n",
    "    if row[ref] > row[group]:\n",
    "        return -1 * (row[ref] / row[group])\n",
    "    else:\n",
    "        return row[group] / row[ref]\n",
    "\n",
    "#normally we wouldn't paste this function here but it helps to show in the lab\n",
    "def flatten(series):\n",
    "    l = []\n",
    "    for x in series:\n",
    "        l.extend(x) #each x is a list we want to unnest\n",
    "    return l\n",
    "    \n",
    "def flatten2(series):\n",
    "    l = []\n",
    "    for x in series:\n",
    "        tmp = set(x) #make the tokens into a set, thus dropping repeats\n",
    "        tmp = list(tmp) #turn it back into a list we can attach to the other lists\n",
    "        l.extend(tmp) \n",
    "    return l\n",
    "\n",
    "def word_use(df, att, ref, per_person=False):\n",
    "    types = list(df[att].value_counts().index.values)\n",
    "    data = {}\n",
    "    lens = {}\n",
    "    \n",
    "    for t in types:\n",
    "        tmp = df[df[att] == t].stems\n",
    "        lens[t] = len(tmp)\n",
    "        \n",
    "        if per_person:\n",
    "            tmp = flatten2(tmp)\n",
    "        else:\n",
    "            tmp = flatten(tmp)\n",
    "        data[t] = Counter(tmp)\n",
    "        \n",
    "    popular_words = pd.DataFrame(data)\n",
    "    \n",
    "    for t in types:\n",
    "        n = 0\n",
    "        \n",
    "        if per_person:\n",
    "            n = lens[t]\n",
    "        else:\n",
    "            n = popular_words[t].sum()\n",
    "        \n",
    "        popular_words[t] = (popular_words[t] / n) * 100\n",
    "    \n",
    "    #find overall most popular words, select the top 1000\n",
    "    popular_words['max'] = popular_words.max(axis=1)\n",
    "    popular_words = popular_words.sort_values(by='max', ascending=False)\n",
    "    popular_words = popular_words.head(1000)\n",
    "    \n",
    "    for t in types:\n",
    "        if t != ref:\n",
    "            popular_words['times_diff_'+t] = popular_words.apply(times_diff2, \n",
    "                                                                 group=t, ref=ref, \n",
    "                                                                 axis=1)\n",
    "\n",
    "    \n",
    "    return popular_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "popular_words = word_use(profiles, att='sex', ref='m')\n",
    "popular_words = popular_words.sort_values(by='times_diff_f', ascending=True)\n",
    "print(\"Men's words:\")\n",
    "popular_words.head(10).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "popular_words = popular_words.sort_values(by='times_diff_f', ascending=False)\n",
    "print(\"Women's words:\")\n",
    "popular_words.head(10).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's try it again, but with percent of profiles rather than percent of words\n",
    "not all profiles have the same number of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "popular_words = word_use(profiles, att='sex', ref='m', per_person=True)\n",
    "popular_words = popular_words.sort_values(by='times_diff_f', ascending=True)\n",
    "print(\"Men's words:\")\n",
    "popular_words.head(10).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "popular_words = popular_words.sort_values(by='times_diff_f', ascending=False)\n",
    "print(\"Women's words:\")\n",
    "popular_words.head(10).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Try it with another trait"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sexual Orientation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = word_use(profiles, att='orientation', ref='straight', per_person=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = result.sort_values(by='times_diff_gay', ascending=False)\n",
    "result.head(10).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = result.sort_values(by='times_diff_bisexual', ascending=False)\n",
    "result.head(10).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = result.sort_values(by='times_diff_gay', ascending=True)\n",
    "result.head(10).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Whether someone is a parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "profiles.offspring.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = word_use(profiles, att='kids', ref='n', per_person=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = result.sort_values(by='times_diff_y', ascending=False)\n",
    "print(\"Top words distinguishing parents:\")\n",
    "result.head(10).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = result.sort_values(by='times_diff_y', ascending=True)\n",
    "print(\"Top words distinguishing non-parents:\")\n",
    "result.head(10).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p2.groupby('kids').age.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = word_use(profiles, att='age_group', ref='20', per_person=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = result.sort_values(by='times_diff_10', ascending=False)\n",
    "print(\"Top words distinguishing teens from 20s:\")\n",
    "result.head(10).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = result.sort_values(by='times_diff_10', ascending=True)\n",
    "print(\"Top words distinguishing 20s from teens:\")\n",
    "result.head(10).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = result.sort_values(by='times_diff_30', ascending=False)\n",
    "print(\"Top words distinguishing 30s from 20s:\")\n",
    "result.head(10).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = result.sort_values(by='times_diff_40', ascending=False)\n",
    "print(\"Top words distinguishing 40s from 20s:\")\n",
    "result.head(10).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = result.sort_values(by='times_diff_50', ascending=False)\n",
    "print(\"Top words distinguishing 50s from 20s:\")\n",
    "result.head(10).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = result.sort_values(by='times_diff_60', ascending=False)\n",
    "print(\"Top words distinguishing 60s from 20s:\")\n",
    "result.head(10).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dogs vs Cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = word_use(p2, att='pets_likes', ref='dogs', per_person=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = result.sort_values(by='times_diff_cats', ascending=False)\n",
    "print(\"Top words distinguishing people with cats:\")\n",
    "result.head(10).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = result.sort_values(by='times_diff_cats', ascending=True)\n",
    "print(\"Top words distinguishing people with dogs:\")\n",
    "result.head(10).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = word_use(profiles, att='edu', ref='BA', per_person=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = result.sort_values(by='times_diff_HS', ascending=False)\n",
    "print(\"Top words distinguishing High School from BAs:\")\n",
    "result.head(10).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = result.sort_values(by='times_diff_HS', ascending=True)\n",
    "print(\"Top words distinguishing BAs from HS:\")\n",
    "result.head(10).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = result.sort_values(by='times_diff_Grad_Pro', ascending=False)\n",
    "print(\"Top words distinguishing graduate and professional degree holders from BAs:\")\n",
    "result.head(10).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = result.sort_values(by='times_diff_Grad_Pro', ascending=True)\n",
    "print(\"Top words distinguishing BAs from Grad/Pro:\")\n",
    "result.head(10).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What we learned\n",
    "Expand for more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
