{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What's in an online dating profile? \n",
    "\n",
    "People say a lot about themselves in online dating profiles, especially on sites like OKCupid that encourage people to answer questions. Thus, we can learn a lot about people by studying what they write. OKC has made some of their profile data from San Fransisco public. We will be using that data in this lab to explore different cultural questions. \n",
    "\n",
    "Our first question is whether and how men and women talk about themselves differently in their profiles. Popular culture is constantly telling us that men and women have different interests, hobbies, and relationship goals. Yet there are also many examples of women who like stereotypically masculine things and men who like feminine ones. This is especially interesting in online dating, because people are seeking partners with similar interests and relationship goals. Finding a partner would be hard for straight men and women if these two groups had very different interests. \n",
    "\n",
    "OKC shared 59,946 profiles though -- way too many to read! Computers can read them all and tell us how common different words are. So our first approach will be simple. We can ask \n",
    "1. Which words are used the most by men and women? \n",
    "2. Which words are used often by men but not women, and vice versa? \n",
    "\n",
    "At the end of the lab, you'll be able to ask this question about other social groups too (like sexual orientation, race/ethnicity, and level of education)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the libraries we'll use.\n",
    "`%matplotlib inline` lets us see charts and plots right here in the notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import regexp_tokenize \n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "profiles = pd.read_csv('data/profiles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A little housekeeping...\n",
    "Expand for more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The OKC data has 10 different columns with profile text, one for each long-answer question in users' profiles.\n",
    "- We want to look at all of the profile text, so this cell merges it all together in a new column called `text`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "essay_cols = ['essay0', 'essay1', 'essay2', 'essay3', 'essay4', 'essay5', 'essay6', \n",
    "              'essay7', 'essay8', 'essay9']\n",
    "\n",
    "ed_levels = {'<HS': ['dropped out of high school', 'working on high school'],\n",
    "             'HS': ['graduated from high school', 'working on college/university', \n",
    "                    'two-year college', 'dropped out of college/university', \n",
    "                    'high school'], \n",
    "             'BA': ['graduated from college/university', \n",
    "                    'working on masters program', 'working on ph.d program', \n",
    "                    'college/university', 'working on law school', \n",
    "                    'dropped out of masters program', \n",
    "                    'dropped out of ph.d program', 'dropped out of law school', \n",
    "                    'dropped out of med school'],\n",
    "             'Grad_Pro': ['graduated from masters program',\n",
    "                          'graduated from ph.d program',                           \n",
    "                          'graduated from law school', \n",
    "                          'graduated from med school', 'masters program', \n",
    "                          'ph.d program', 'law school', 'med school']\n",
    "            }\n",
    "\n",
    "bodies = {'average': ['average'], \n",
    "          'fit': ['fit', 'athletic', 'jacked'], \n",
    "          'thin': ['thin', 'skinny'], \n",
    "          'overweight': ['curvey', 'a little extra', 'full figured', 'overweight']\n",
    "         }\n",
    "\n",
    "smoke = {'no': ['no'], np.nan: ['nan']}\n",
    "\n",
    "kids = {'yes': ['has a kid', 'has kids']}\n",
    "\n",
    "has_pets = {'yes': ['has']}\n",
    "\n",
    "ethn = {'White': ['white', 'middle eastern', 'middle eastern, white'], \n",
    "        'Asian': ['asian', 'indian', 'asian, pacific islander'], \n",
    "        'Black': ['black']\n",
    "       }   \n",
    "\n",
    "ethn2 = {'Latinx': ['latin'], 'multiple': [','], np.nan: ['nan']}   \n",
    "\n",
    "drinks = {'no': ['rarely', 'not at all']}\n",
    "\n",
    "drugs = {'no': ['never']}\n",
    "\n",
    "jobs = {'education': ['student', 'education'], \n",
    "        'STEM': ['science', 'computer'], \n",
    "        'business': ['sales', 'executive', 'banking'], \n",
    "        'creative': ['artistic', 'entertainment'], \n",
    "        'med_law': ['medicine', 'law'],\n",
    "        np.nan: ['nan']\n",
    "       }\n",
    "\n",
    "religion = {'none': ['agnosticism', 'atheism'],\n",
    "            'catholicism': ['catholicism'],\n",
    "            'christianity': ['christianity'],\n",
    "            'judaism': ['judaism'],\n",
    "            'buddhism': ['buddhism'],\n",
    "            np.nan: ['nan']\n",
    "           }\n",
    "\n",
    "languages = {'multiple': [',']}\n",
    "\n",
    "\n",
    "def concat(row, cols):\n",
    "    tmp = []\n",
    "    for c in cols:\n",
    "        tmp.append(str(row[c]))\n",
    "    new = '\\n'.join(tmp)\n",
    "    return new\n",
    "\n",
    "def recode(text, dictionary, default=np.nan):\n",
    "    out = default\n",
    "    text = str(text)\n",
    "    \n",
    "    for x in dictionary.keys():\n",
    "        for y in dictionary[x]:\n",
    "            if y == text:\n",
    "                out = x\n",
    "                return out\n",
    "    return out\n",
    "\n",
    "def recode_fuzzy(text, dictionary, default=np.nan):\n",
    "    out = default\n",
    "    text = str(text)\n",
    "    \n",
    "    for x in dictionary.keys():\n",
    "        for y in dictionary[x]:\n",
    "            if y in text:\n",
    "                out = x\n",
    "                return out\n",
    "    return out\n",
    "\n",
    "\n",
    "def which_pets(t, criterion='has'):\n",
    "    d = False\n",
    "    c = False\n",
    "    t = str(t)\n",
    "    p = 'neither'\n",
    "    if t == 'nan':\n",
    "        p = np.nan\n",
    "    \n",
    "    if 'has dogs' in t:\n",
    "        d = True\n",
    "    if 'has cats' in t:\n",
    "        c = True\n",
    "        \n",
    "    if criterion == 'likes':\n",
    "        if 'likes dogs' in t:\n",
    "            if 'dislikes dogs' not in t:\n",
    "                d = True\n",
    "        if 'likes cats' in t:\n",
    "            if 'dislikes cats' not in t:\n",
    "                c = True\n",
    "        \n",
    "    if c and d:\n",
    "        p = 'both'\n",
    "    elif c:\n",
    "        p = 'cats'\n",
    "    elif d:\n",
    "        p = 'dogs'\n",
    "        \n",
    "    return p\n",
    "\n",
    "def census_2010_ethnicity(t):\n",
    "    '''\n",
    "    Function gathers choices for this question gathered by the US Census 2010.\n",
    "    It deviates from the census by creating exclusive Latinx category. Selecting \n",
    "    just 'latin' and nothing else was the 3rd most frequent ethnicity in this \n",
    "    data. The discision to include people who identified 'latin' and another race\n",
    "    is based in research on Latinx people's experience with the US Census, but \n",
    "    like all racial and ethnic categorization systems it is flawed. \n",
    "    '''\n",
    "    text = str(t)\n",
    "    \n",
    "    e = recode(text, ethn, default='other')\n",
    "    if 'other' == e:\n",
    "        e = recode_fuzzy(text, ethn2, default='other')\n",
    "    \n",
    "    return e\n",
    "\n",
    "def height(inches):\n",
    "    h = 'under_6'\n",
    "    if inches >= 72:\n",
    "        h = 'over_6'\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove people 60+ and 17-\n",
    "profiles = profiles[(profiles.age < 60) & (profiles.age > 17)]\n",
    "\n",
    "profiles['text'] = profiles.apply(concat, axis=1, cols=essay_cols)\n",
    "profiles['edu'] = profiles.education.apply(recode, dictionary=ed_levels, \n",
    "                                            default='unknown')\n",
    "profiles['kids'] = profiles.offspring.apply(recode_fuzzy, dictionary=kids, \n",
    "                                            default='no')\n",
    "profiles['pets_likes'] = profiles.pets.apply(which_pets, criterion='likes')\n",
    "profiles['pets_has'] = profiles.pets.apply(which_pets, criterion='has')\n",
    "profiles['pets_any'] = profiles.pets.apply(recode_fuzzy, dictionary=has_pets, \n",
    "                                            default='no')\n",
    "profiles['age_group'] = profiles.age.apply(lambda x: str(int(x/10)*10))\n",
    "profiles['height_group'] = profiles.height.apply(height)\n",
    "profiles['race_ethnicity'] = profiles.ethnicity.apply(census_2010_ethnicity)\n",
    "profiles['smoker'] = profiles.smokes.apply(recode, dictionary=smoke, \n",
    "                                            default='yes')\n",
    "profiles['body'] = profiles.body_type.apply(recode, dictionary=bodies, \n",
    "                                            default='unknown')\n",
    "profiles['alcohol_use'] = profiles.drinks.apply(recode, dictionary=drinks, \n",
    "                                            default='yes')\n",
    "profiles['drug_use'] = profiles.drugs.apply(recode, dictionary=drugs, \n",
    "                                            default='yes')\n",
    "profiles['industry'] = profiles.job.apply(recode_fuzzy, dictionary=jobs, \n",
    "                                            default='other')\n",
    "profiles['religion'] = profiles.religion.apply(recode_fuzzy, dictionary=religion, \n",
    "                                            default='other')\n",
    "profiles['languages'] = profiles.speaks.apply(recode_fuzzy, dictionary=languages, \n",
    "                                            default='English_only')\n",
    "\n",
    "profiles = profiles[['age_group', 'body', 'alcohol_use', 'drug_use', 'edu', \n",
    "                     'race_ethnicity', 'height_group', 'industry', 'kids', \n",
    "                     'orientation', 'pets_likes', 'pets_has', 'pets_any', \n",
    "                     'religion', 'sex', 'smoker', 'languages', 'text']]\n",
    "\n",
    "profiles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "profiles.to_csv('data/clean_profiles.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#random subsample so this doesn't crash on laptops\n",
    "profiles = profiles.sample(20000)\n",
    "profiles = profiles.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's peak at an example of the text so we know what we're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles.text[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### We want to split the text into words.\n",
    "Expand for details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- We can do this by applying the `split()` function to text in every profile. \n",
    "- Notice, however, that this is a little messy.\n",
    "    - `split()` is just cutting up the text based on the spaces, leaving the punctuation and some HTML things mized in with our words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A first try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = profiles['text'].apply(lambda x: x.split())\n",
    "tmp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting text from words\n",
    "Expand for details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define a function to clean up the text a bit more. It does a few things:\n",
    "- Removes HTML code from the text using BeautifulSoup. (Remember, we want just the words people actually typed.) \n",
    "- Converts all of the text to lowercase, so that `Hello`, `hello`, `\"HeLlO`, and `HELLO` all look the same to the computer.\n",
    "- Uses the Natural Language Tool Kit (`nltk`) to tokenize the remaining text. \n",
    "    - \"Tokenize\" is jargon for splitting text into \"tokens.\" Tokens are usually words, but they could be sentences, paragraphs, letters, or whatever we needed. \n",
    "    - The nltk tokenizers are much smarter than the simple `string.split()` function we used before. This one (which we imported in the beginning) selects the words, but ignores the whitespace and punctuation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A second try"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_words = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \n",
    "              'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', \n",
    "              'himself', 'she', 'her', 'hers', 'herself', 'they', 'them', 'their',\n",
    "              'theirs', 'themselves']\n",
    "\n",
    "sw = set(stopwords.words('english'))\n",
    "\n",
    "for k in keep_words:\n",
    "    sw.discard(k) #could use remove if we wanted keyerrors\n",
    "    \n",
    "print(sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    t = BeautifulSoup(text, 'lxml').get_text()\n",
    "    \n",
    "    bad_words = ['http', 'www', '\\nnan']\n",
    "    for b in bad_words:\n",
    "        t = t.replace(b, '')\n",
    "    \n",
    "    t = t.lower()\n",
    "    t = regexp_tokenize(t, '\\w+')\n",
    "    \n",
    "    final = []\n",
    "    for w in t:\n",
    "        if w not in sw:\n",
    "            final.append(w)\n",
    "    \n",
    "    return final\n",
    "\n",
    "profiles['tokens'] = profiles['text'].apply(clean)\n",
    "profiles.tokens.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Comparing the words used by men and women"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "men = profiles[(profiles['sex'] == 'm') & (profiles['orientation'] == 'straight')]\n",
    "women = profiles[(profiles['sex'] == 'f') & (profiles['orientation'] == 'straight')]\n",
    "\n",
    "men.tokens.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Counting how often each gender uses each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(series):\n",
    "    l = []\n",
    "    for x in series:\n",
    "        l.extend(x) #each x is a list we want to unnest\n",
    "    return l\n",
    "\n",
    "tmp = flatten(men.tokens)\n",
    "\n",
    "mens_words = Counter(tmp)\n",
    "mens_words.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = flatten(women.tokens)\n",
    "\n",
    "womens_words = Counter(tmp)\n",
    "womens_words.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert those word counts to frequencies (percent of total words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = {'women': womens_words,\n",
    "       'men': mens_words\n",
    "      }\n",
    "\n",
    "popular_words = pd.DataFrame(tmp)\n",
    "\n",
    "popular_words['men'] = (popular_words['men'] /  popular_words['men'].sum())*100\n",
    "popular_words['women'] = (popular_words['women'] /  popular_words['women'].sum())*100\n",
    "\n",
    "popular_words.sort_values(by='men', inplace=True, ascending=False)\n",
    "popular_words.head().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_words['max'] = popular_words.max(axis=1)\n",
    "popular_words = popular_words.sort_values(by='max', ascending=False)\n",
    "popular_words.head(10).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### See the distribution of word popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_words['max'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look at just the 1000 most popular words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_words = popular_words.head(1000)\n",
    "print(popular_words.shape)\n",
    "popular_words['max'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure out which words are popular with one gender but not the other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def times_diff(row):\n",
    "    if row.men > row.women:\n",
    "        return row.men / row.women\n",
    "    else:\n",
    "        return -1 * (row.women / row.men)\n",
    "    \n",
    "popular_words['times_diff'] = popular_words.apply(times_diff, axis=1)\n",
    "popular_words = popular_words.sort_values(by='max', ascending=False)\n",
    "\n",
    "print('Most popular words:')\n",
    "popular_words.head(10).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_words = popular_words.sort_values(by='times_diff', ascending=False)\n",
    "\n",
    "print('Words men use more than women:')\n",
    "popular_words.head(15).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_words = popular_words.sort_values(by='times_diff', ascending=True)\n",
    "\n",
    "print('Words women use more than men:')\n",
    "popular_words.head(15).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#snowball English (aka porter2) is improved over the porter stemmer\n",
    "stemmer = SnowballStemmer(\"english\") \n",
    "\n",
    "def stem(t):\n",
    "    out = []\n",
    "    for w in t:\n",
    "        out.append(stemmer.stem(w))\n",
    "    return out\n",
    "\n",
    "profiles['stems'] = profiles['tokens'].apply(stem)\n",
    "profiles.stems.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's try it again with stems this time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for summarizing word use by a trait\n",
    "def times_diff2(row, group, ref):\n",
    "    if row[ref] > row[group]:\n",
    "        return -1 * (row[ref] / row[group])\n",
    "    else:\n",
    "        return row[group] / row[ref]\n",
    "\n",
    "#normally we wouldn't paste this function here but it helps to show in the lab\n",
    "def flatten(series):\n",
    "    l = []\n",
    "    for x in series:\n",
    "        l.extend(x) #each x is a list we want to unnest\n",
    "    return l\n",
    "    \n",
    "def flatten2(series):\n",
    "    l = []\n",
    "    for x in series:\n",
    "        tmp = set(x) #make the tokens into a set, thus dropping repeats\n",
    "        tmp = list(tmp) #turn it back into a list we can attach to the other lists\n",
    "        l.extend(tmp) \n",
    "    return l\n",
    "\n",
    "\n",
    "def count(data, per_person):\n",
    "    #count the people in each category\n",
    "    l = len(data)\n",
    "\n",
    "    #apply the right aggregation function, depending whether we want \n",
    "    #most common words, or words used by most people\n",
    "    if per_person:\n",
    "        data = flatten2(data)\n",
    "    else:\n",
    "        data = flatten(data)\n",
    "            \n",
    "    c = Counter(data)\n",
    "    \n",
    "    return c, l\n",
    "\n",
    "def word_use(df, att, ref=None, per_person=False):\n",
    "    #list all of the categories in this column\n",
    "    types = list(df[att].value_counts().index.values)\n",
    "    #variables that will store our results\n",
    "    data = {}\n",
    "    lens = {}\n",
    "    \n",
    "    for t in types:\n",
    "        #get the stems for each category\n",
    "        tmp = df[df[att] == t].stems\n",
    "        #count how often each is used\n",
    "        data[t], lens[t] = count(tmp, per_person)\n",
    "        \n",
    "        #also compute the inverse of each category\n",
    "        tmp = df[df[att] != t].stems\n",
    "        data['not_'+t], lens['not_'+t] = count(tmp, per_person)        \n",
    "        \n",
    "    #convert those results to a pandas data frame for easy handling\n",
    "    popular_words = pd.DataFrame(data)\n",
    "    \n",
    "    # convert the counts in each column to percents\n",
    "    for t in popular_words.columns:\n",
    "        n = lens[t] #if we want percent of people\n",
    "        \n",
    "        if not per_person: #if we want percent of total words \n",
    "            n = popular_words[t].sum()\n",
    "        \n",
    "        popular_words[t] = (popular_words[t] / n) * 100\n",
    "    \n",
    "    #find overall most popular words\n",
    "    popular_words['max'] = popular_words.max(axis=1)\n",
    "    \n",
    "    #sort the words and select the top 1000 most popular\n",
    "    popular_words = popular_words.sort_values(by='max', ascending=False)\n",
    "    popular_words = popular_words.head(1000)\n",
    "\n",
    "    #calculate the rate each type of person uses these words relative to others\n",
    "    for t in types:\n",
    "        r = ref\n",
    "        \n",
    "        if ref == None: #if we do not have a reference category, use the inverse\n",
    "            r = 'not_'+t\n",
    "            \n",
    "        if t != ref: #don't compare a trait to itself\n",
    "            #apply our times_diff2 function\n",
    "            popular_words['times_diff_'+t] = popular_words.apply(times_diff2, \n",
    "                                                                 group=t, \n",
    "                                                                 ref=r, \n",
    "                                                                 axis=1)\n",
    "\n",
    "    #remove the inverse columns we created\n",
    "    popular_words = popular_words.drop(popular_words.filter(regex='not_'), axis=1)\n",
    "    \n",
    "    return popular_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_words = word_use(profiles, att='sex')\n",
    "popular_words = popular_words.sort_values(by='times_diff_m', ascending=False)\n",
    "print(\"Men's words:\")\n",
    "popular_words.head(10).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_words = popular_words.sort_values(by='times_diff_f', ascending=False)\n",
    "print(\"Women's words:\")\n",
    "popular_words.head(10).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's try it again, but with percent of profiles rather than percent of words\n",
    "not all profiles have the same number of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_words = word_use(profiles, att='sex', per_person=True)\n",
    "popular_words = popular_words.sort_values(by='times_diff_m', ascending=False)\n",
    "print(\"Men's words:\")\n",
    "popular_words.head(10).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_words = popular_words.sort_values(by='times_diff_f', ascending=False)\n",
    "print(\"Women's words:\")\n",
    "popular_words.head(10).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Try it with another trait"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Options (traits)\n",
    "We have a lot more information about people than just whether they're men or women. Try the analysis again with one of these other traits. (Expand for a list.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- age_group (How old someone is. Youngest users are 18.)\n",
    "    - categories: ['10', '20', '30', '40', '50']\n",
    "- body (self-described)\n",
    "    - categories: ['fit', 'average', 'thin', 'overweight', 'unknown']\n",
    "- alcohol_use\n",
    "    - categories: ['yes', 'no']\n",
    "- drug_use\n",
    "    - categories: ['yes', 'no']\n",
    "- edu (highest degree completed)\n",
    "    - categories: ['`<HS`', 'HS', 'BA', 'Grad_Pro', 'unknown'] \n",
    "- race_ethnicity\n",
    "    - categories: ['White', 'Asian', 'Latinx', 'multiple', 'other', 'Black']\n",
    "- height_group (whether someone is over or under six feet tall)\n",
    "    - categories: ['under_6', 'over_6']\n",
    "- industry (what field they work in)\n",
    "    - categories: ['STEM', 'business', 'education', 'creative', 'med_law', 'other'] \n",
    "- kids (whether they have children)\n",
    "    - categories: ['yes', 'no']\n",
    "- orientation\n",
    "    - categories: ['straight', 'gay', 'bisexual']\n",
    "- pets_likes (what pets they like)\n",
    "    - categories: ['both', 'dogs', 'cats', 'neither']\n",
    "- pets_has (what pets they have)\n",
    "    - categories: ['both', 'dogs', 'cats', 'neither']\n",
    "- pets_any (whether they have pets or not)\n",
    "    - categories: ['yes', 'no']\n",
    "- religion\n",
    "    - categories: ['christianity', 'catholicism', 'judaism', 'buddhism', 'none', 'other'] \n",
    "- sex\n",
    "    - categories: ['m', 'f']\n",
    "- smoker\n",
    "    - categories: ['yes', 'no']\n",
    "- languages\n",
    "    - categories: ['multiple', 'English_only'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to (steps)\n",
    "#### Step 1a: Decide which of the traits above you want to look at.\n",
    "#### Step 1b: Load the profile data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#open the data we cleaned and saved earlier. This is the same for everyone. \n",
    "profiles = pd.read_csv('data/clean_profiles.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Step 2: If you want, limit the data to just men or women.\n",
    "- For only men, leave this code how it is.\n",
    "- For only women, change the `'m'` in this line to `'f'`\n",
    "- For all people, add a `#` at the start of this line to comment it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles = profiles[profiles['sex'] == 'm']\n",
    "\n",
    "#if you're running on a laptop, it is smart to use a smaller amount of data\n",
    "profiles = profiles.sample(20000)\n",
    "profiles.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Tokenize and stem the text for these profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tokenizing...\")\n",
    "profiles['tokens'] = profiles['text'].apply(clean)\n",
    "print(\"Stemming...\")\n",
    "profiles['stems'] = profiles['tokens'].apply(stem)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Compute the word usage statistics for your chosen attribute.\n",
    "You can change two things in the code below:\n",
    "- You can change `att='sex'` to your attribute of interest (e.g. `body` or `orientation`)\n",
    "- You can change `per_person=True` to `False` if you want to see which words are used most often, rather than which words are used by the most people. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = word_use(profiles, att='sex', per_person=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5a: Look at the results\n",
    "First, let's just see what columns we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.head(2).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5b: Looking at the most distinctive words by category\n",
    "You can change two things in this code:\n",
    "1. Change `'times_diff_f'` to the name of the column you want to sort by, i.e. the column you want to see the most popular words in. \n",
    "2. Change the number in `head(10)` to a bigger or smaller number to see more or less rows of output.\n",
    "\n",
    "You can paste this line into more cells below to show different groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.sort_values(by='times_diff_f', ascending=False).head(10).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Sexual Orientation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "result = word_use(profiles, att='orientation', per_person=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "result = result.sort_values(by='times_diff_gay', ascending=False)\n",
    "result.head(10).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "result = result.sort_values(by='times_diff_bisexual', ascending=False)\n",
    "result.head(10).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "result = result.sort_values(by='times_diff_straight', ascending=False)\n",
    "result.head(10).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Whether someone is a parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "result = word_use(profiles, att='kids', per_person=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "result = result.sort_values(by='times_diff_no', ascending=True)\n",
    "print(\"Top words distinguishing parents:\")\n",
    "result.head(10).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "result = result.sort_values(by='times_diff_yes', ascending=True)\n",
    "print(\"Top words distinguishing non-parents:\")\n",
    "result.head(10).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "result = word_use(profiles, att='age_group', per_person=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "result = result.sort_values(by='times_diff_10', ascending=False)\n",
    "print(\"Top words distinguishing teens:\")\n",
    "result.head(10).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "result = result.sort_values(by='times_diff_20', ascending=False)\n",
    "print(\"Top words distinguishing 20s:\")\n",
    "result.head(10).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "result = result.sort_values(by='times_diff_30', ascending=False)\n",
    "print(\"Top words distinguishing 30s:\")\n",
    "result.head(10).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "result = result.sort_values(by='times_diff_40', ascending=False)\n",
    "print(\"Top words distinguishing 40s:\")\n",
    "result.head(10).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "result = result.sort_values(by='times_diff_50', ascending=False)\n",
    "print(\"Top words distinguishing 50s:\")\n",
    "result.head(10).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Dogs vs Cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "result = word_use(p2, att='pets_likes', ref='dogs', per_person=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "result = result.sort_values(by='times_diff_cats', ascending=False)\n",
    "print(\"Top words distinguishing people with cats:\")\n",
    "result.head(10).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "result = result.sort_values(by='times_diff_cats', ascending=True)\n",
    "print(\"Top words distinguishing people with dogs:\")\n",
    "result.head(10).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "result = word_use(profiles, att='edu', ref='BA', per_person=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "result = result.sort_values(by='times_diff_HS', ascending=False)\n",
    "print(\"Top words distinguishing High School from BAs:\")\n",
    "result.head(10).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "result = result.sort_values(by='times_diff_HS', ascending=True)\n",
    "print(\"Top words distinguishing BAs from HS:\")\n",
    "result.head(10).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "result = result.sort_values(by='times_diff_Grad_Pro', ascending=False)\n",
    "print(\"Top words distinguishing graduate and professional degree holders from BAs:\")\n",
    "result.head(10).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "result = result.sort_values(by='times_diff_Grad_Pro', ascending=True)\n",
    "print(\"Top words distinguishing BAs from Grad/Pro:\")\n",
    "result.head(10).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What we learned\n",
    "Expand for more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
